{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Approximation through the empirical interpolation method (EIM)\n",
    "\n",
    "The empirical interpolation method (EIM) seeks to approximate a family of parametric functions using a sensibly chosen linear space of moderate dimension, and some interpolation points. Any function in this parametric family can then be approximated globally by simply evaluating it at the interpolation points, then filling in using the linear interpolator.\n",
    "\n",
    "<img src=\"./interp_example.png\">\n",
    "\n",
    "This Notebook demo performs EIM on a simple example parametric function using only code from this Notebook. There are some crucial steps left to fill in, as an exercise for the workshop participant.\n",
    "\n",
    "### First we need to do a little housekeeping\n",
    "\n",
    "We import the libraries we require:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Latex, display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm \n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following snippet stops the automatic truncation of cell output when it gets too long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define a little helper function for plotting our functions on grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.inferno\n",
    "\n",
    "def plot_R2_function(vals, ax, title=None, alpha=0.7):\n",
    "    # A routine that just plots a function that is assumed to be evaluated \n",
    "    # on a the grid of points - vals is assumed to be a square array\n",
    "    # (note that x1_grid and x2_grid will be defined below)\n",
    "    wframe = ax.plot_surface(x1_grid, x2_grid, vals, cstride=5, rstride=5, \n",
    "                             alpha=alpha, cmap=cmap)\n",
    "    \n",
    "    ax.set_facecolor('white')\n",
    "    if title is not None:\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Lets get started! \n",
    "### First we need to define a family of functions that we want to interpolate\n",
    "\n",
    "Lets start with a simple family of parametric functions given by\n",
    "\n",
    "$$\\large\n",
    "y(x, \\mu) = \\frac{2}{\\| x - \\mu \\|}\n",
    "$$\n",
    "\n",
    "where $\\large x \\in \\mathcal{D} = [0,1]^2$ is two dimensional, and the parameter  $\\large \\mu \\in \\mathcal{U} = [1.1, 2.1]^2$.\n",
    "\n",
    "(We can define whatever we want for $\\mathcal{D}$ in ```x_lims``` or for $\\mathcal{U}$ in  ```mu_lims```)\n",
    "\n",
    "Below we define a grid for $x$ on $\\mathcal{D} = [0,1]^2$, and a grid of possible parameters $\\mu$ in $\\mathcal{U} = [1.1, 2.1]^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lims = [[0,1], [0,1]]\n",
    "mu_lims = [[1.1, 2.1], [1.1, 2.1]]\n",
    "\n",
    "n_x_grid = 100\n",
    "n_mu_grid = 100\n",
    "\n",
    "mu1_grid, mu2_grid = np.meshgrid(np.linspace(mu_lims[0][0], mu_lims[0][1], n_mu_grid+1, endpoint=True), \n",
    "                                 np.linspace(mu_lims[1][0], mu_lims[1][1], n_mu_grid+1, endpoint=True))\n",
    "x1_grid, x2_grid = np.meshgrid(np.linspace(x_lims[0][0], x_lims[0][1], n_x_grid+1, endpoint=True), \n",
    "                               np.linspace(x_lims[1][0], x_lims[1][1], n_x_grid+1, endpoint=True))\n",
    "\n",
    "# We make a flattened list of all the points in the grid for x or mu\n",
    "# If we call mu_grid_list[i] we will get an array of length 2, [mu_1, mu_2] \n",
    "mu_grid_list = np.vstack((mu1_grid.flatten(), mu2_grid.flatten())).T\n",
    "x_grid_list = np.vstack((x1_grid.flatten(), x2_grid.flatten())).T\n",
    "\n",
    "# Just how many possible parameters have we generated?\n",
    "print('Number of mu parameters in grid:', mu_grid_list.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y(x, mu):\n",
    "    # This definition of y can take a list of multiple values for x or mu\n",
    "    # (because of the behaviour of np.linalg.norm with axis=1)\n",
    "    return 2.0 / np.linalg.norm(x - mu, axis=1)\n",
    "\n",
    "def eval_y_on_grid(mu):\n",
    "    # This evaluates y on the grid using the pre-computed x_grid_list\n",
    "    return y(x_grid_list, mu).reshape((n_x_grid+1, n_x_grid+1))\n",
    "\n",
    "display(Latex(r'We plot two instances of $y(x,\\mu)$'))\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "mu_test = np.array([1.1, 1.9])\n",
    "plot_R2_function(eval_y_on_grid(mu_test), ax, \n",
    "                 title=rf'$y(x,\\mu_{{test}})$, where $\\mu_{{test}} = $ {mu_test}')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "mu_test = np.array([1.9, 1.1])\n",
    "plot_R2_function(eval_y_on_grid(mu_test), ax, \n",
    "                 title=rf'$y(x,\\mu_{{test}})$, where $\\mu_{{test}} = $ {mu_test}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Generate a training set \n",
    "\n",
    "We evaluate the function $y(x, \\mu)$ for each $\\mu$ in a set of parameters $\\mathcal{T} \\subset \\mathcal{U}$. \n",
    "\n",
    "We can take $\\mathcal{T}$ to simply be the list of grid points ```mu_grid_list```, defined earlier. These evaluations of $y(x, \\mu_i)$ are saved in ```training_set```.\n",
    "\n",
    "The number of training set points $N$ is determined by the grid we defined earlier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the training set: a collection of g evaluated for every mu in mu_grid_list\n",
    "training_set = [eval_y_on_grid(mu) for mu in mu_grid_list]\n",
    "\n",
    "N = len(training_set)\n",
    "print('N =', N, 'is the number of training set points')\n",
    "print('Element 0 is a NumPy array of dimension', training_set[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Define routines to assemble $\\mathbf{B}$ and the interpolation $\\mathcal{I}_n(g)$\n",
    "\n",
    "The interpolator that we wish to construct is a linear system of the form\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\mathcal{I}_n( y(x, \\mu) ) = \\sum_{j=1}^n {\\alpha_j(\\mu)} \\, { q_j(x)}\n",
    "$$\n",
    "\n",
    "This matrix is used in the next step of evaluating the interpolator $\\mathcal{I}_n(q)$. We require our interpolation scheme to be exact on the interpolation points $(x_i)_{i=1}^n$, that is we require\n",
    "$$\n",
    "\\large\n",
    "\\mathcal{I}_n( y(x_i, \\mu) ) = y(x_i, \\mu)\n",
    "$$\n",
    "\n",
    "This means that we enforce\n",
    "$$\n",
    "\\large\n",
    "\\sum_{j=1}^n \\alpha_j(\\mu) \\, q_j(x_i) = y(x_i, \\mu)\n",
    "$$\n",
    "which is equivalent to the linear system\n",
    "$$\n",
    "\\large\n",
    "\\mathbf{B} \\mathbf{\\alpha} = \\mathbf{y}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{B} \\in \\mathbb{R}^{n\\times n}$ and $\\mathbf{\\alpha}, \\mathbf{y} \\in \\mathbb{R}^n$ are the matrix and coefficient vectors with values\n",
    "\n",
    "$$\\large\n",
    "\\begin{aligned}\n",
    "(\\mathbf{B})_{i,j} &= q_j(x_i) \\\\[5pt]\n",
    "(\\mathbf{y})_i &= y(x_i, \\mu) \\\\[5pt]\n",
    "(\\mathbf{\\alpha})_j &= \\alpha_j(\\mu) \\quad\\text{   (the unknowns!)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Thus we see there are __two__ crucial steps in EIM. As such, we will define two routines:\n",
    " - ```build_B_matrix``` that constructs $\\mathbf{B}$, and\n",
    " - ```interpolator``` that calculates $\\mathcal{I}_n[y(x, \\mu)]$, it takes the inverse $\\mathbf{B}^{-1}$ and uses it to calculate the $\\alpha_i(\\mu)$, which are labelled ```alpha_coeffs[i]``` in the code. To calculate ```alpha_coeffs``` we require the function evaluations $y(x_i, \\mu)$ which are stored in ```func_eval[i]```.\n",
    " \n",
    "__Question__: Why would we define $\\mathbf{B}$ separately and then use its inverse $\\mathbf{B}^{-1}$, rather than just calling a linear solver line ```np.linalg.solve```?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_B_matrix(interp_funcs, interp_points):\n",
    "\n",
    "    # ===================\n",
    "    #  FILL IN CODE HERE\n",
    "    # ===================\n",
    "    # Make the B matrix. Use np.zeros() to define a matrix of zeros\n",
    "    # Assume interp_funcs is a list [] of square arrays and\n",
    "    # interp_points is a list [] of 2-element arrays that are \n",
    "    # indices for those square arrays\n",
    "\n",
    "def interpolator(func, B_inv, interp_funcs, interp_points):\n",
    "    \n",
    "    # ===================\n",
    "    #  FILL IN CODE HERE\n",
    "    # ===================\n",
    "    # 1. Evaluate func at the interp_points, store in func_evals\n",
    "    #    N.B. We call func[inter_point] as it is an array of function evaluations on a grid\n",
    "    #    (In some other setting func we may actually want func(inter_point))\n",
    "    #    \n",
    "    # 2. Find the coefficients alpha from B_inv and these func_evals\n",
    "    #\n",
    "    # 3. Build the interpolant by mulitplying alpha[i] by the interp_funcs\n",
    "    \n",
    "    return interpolant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - implement the iterations of the EIM\n",
    "\n",
    "### The first iteration:\n",
    "\n",
    "$$ \\large\n",
    "\\begin{aligned}\n",
    "\\mu_1 &= {\\arg \\max}_{\\mu \\in \\mathcal{T}} \\| y(x, \\mu) \\| \\\\[5pt]\n",
    "x_1 &= {\\arg \\max}_{x \\in \\mathcal{D}} | y(x, \\mu_1) | \\\\[5pt]\n",
    "q_1 &= \\frac{y(x, \\mu_1)} { y(x_1, \\mu_1)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Note that we are saving the interpolation functions $\\large q_i$ in the list ```interp_funcs``` and the interpolation points $\\large x_i$ in the list ```interp_points```.\n",
    "\n",
    "First we define helper functions that gives us the __location__ of the maximum of an array of function values ```func```, as well as the $L^2$ and $L^\\infty$ norms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax_2d(func):\n",
    "    # this returns the indices of where the maximum is located in a 2-d array\n",
    "    # necessary due to the standard behaviour of NumPy's argmax() function\n",
    "    return np.unravel_index(np.argmax(func), func.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(func_vals):\n",
    "    # A little helper function that calculates the L^2 norm of a function that\n",
    "    # is evaluated on the regular x grid.\n",
    "    return np.linalg.norm(func_vals) / (n_x_grid * n_x_grid)\n",
    "\n",
    "def L_inf_norm(func_vals):\n",
    "    return np.abs(func_vals).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = []\n",
    "interp_funcs = []\n",
    "interp_points = []\n",
    "\n",
    "# ===================\n",
    "#  FILL IN CODE HERE\n",
    "# ===================\n",
    "# How do we make the first choice for mu_1 and x_1? Review the notes above.\n",
    "# We need to find argmax of the norms of each member of the training set.\n",
    "# You could use np.argmax( ) for example...\n",
    "norms = # The norm of each member of the training set\n",
    "first_choice = # The location of the largest norm in the training set\n",
    "first_x = # The location of the point in this choice with largest absolute value\n",
    "\n",
    "# Now we add our first selection and the first interpolation point \n",
    "# to the list\n",
    "selected.append(first_choice)\n",
    "interp_points.append(first_x)\n",
    "\n",
    "# ===================\n",
    "#  FILL IN CODE HERE\n",
    "# ===================\n",
    "# We want to \"normalise\" our first choice of function to obtain the first \n",
    "# interpolation function q_i and add it to interp_funcs\n",
    "#\n",
    "# use .append()\n",
    "\n",
    "# Lets take a look at what we've chosen\n",
    "display(Latex(r'We plot the first choice $y(x, \\mu_1)$, and label $x_1$, as well as $q_1(x)$'))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "plot_R2_function(training_set[first_choice], ax, title = rf'$y(x, \\mu_1)$')\n",
    "ax.scatter(first_x[1] / n_x_grid, first_x[0] / n_x_grid, training_set[first_choice][first_x], s=30)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "plot_R2_function(interp_funcs[-1], ax, title = rf'$q_1(x)$')\n",
    "plt.show()\n",
    "\n",
    "display(Latex(rf'The point $x_{1}$ is at index {first_x} which ' +\n",
    "              rf'gives the coordinate $x_{1} = {{{first_x[1]/n_x_grid, first_x[0]/n_x_grid}}}$ ' +\n",
    "              rf'(marked by the blue dot)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Then at iteration $n$\n",
    "\n",
    "Assume we have built a collection of interpolation functions $(q_1,\\ldots,q_{n-1})$ and interpolation points $(x_1,\\ldots,x_{n-1})$. From these we can define $\\mathcal{I}_{n-1}[y(x, mu)]$ as in __Step 3__. Then we find\n",
    "\n",
    "$$ \\large\n",
    "\\begin{aligned}\n",
    "\\mu_n &= {\\arg \\max}_{\\mu \\in \\mathcal{T}}  \\| y(x, \\mu) - \\mathcal{I}_{n-1}[ y(x, \\mu) ] \\| \\\\[5pt]\n",
    "x_n &= {\\arg \\max}_{x\\in\\mathcal{D}} | y(x, \\mu_n) | \\\\[5pt]\n",
    "q_n &= \\frac{y(x, \\mu_n) - \\mathcal{I}_{n-1}[y(x, \\mu_n)]} { y(x_n, \\mu_n) - \\mathcal{I}_{n-1}[y(x_n, \\mu_n)]}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We must use the two routines we defined earlier: \n",
    " - ```build_B_matrix(interp_funcs, interp_points)``` and \n",
    " - ```interpolator(func, B_inv, interp_funcs, interp_points)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10 # The number of iterations = num of interpolation points and functions\n",
    "\n",
    "# We need to calculate the initial B matrix (it is only a 1x1 matrix, but still...)\n",
    "B = build_B_matrix(interp_funcs, interp_points)\n",
    "B_inv = np.linalg.inv(B)\n",
    "\n",
    "for n in range(2,n_iter+1):\n",
    "    \n",
    "    # Now we can construct the vector for each function\n",
    "    resids = np.zeros(len(training_set))\n",
    "    # ===================\n",
    "    #  FILL IN CODE HERE\n",
    "    # ===================\n",
    "    # We want to calculate the norm of the \"residual\" from the interpolation\n",
    "    # of each member of the training set. \n",
    "    # Loop through the whole training set and compute\n",
    "\n",
    "    \n",
    "    next_choice = np.argmax(resids)\n",
    "    selected.append(next_choice)\n",
    "\n",
    "    # ===================\n",
    "    #  FILL IN CODE HERE\n",
    "    # ===================\n",
    "    # take the selected function, and calculate its residual (again),\n",
    "    # for later calculation of q_n\n",
    "    selected_func = # ???\n",
    "    selected_func_resid = # ???\n",
    "    \n",
    "    # Now choose x_n - note that it is an index of where the maximum is located on the grid\n",
    "    next_x = argmax_2d(selected_func_resid)\n",
    "    interp_points.append(next_x)\n",
    "    \n",
    "    # ===================\n",
    "    #  FILL IN CODE HERE\n",
    "    # ===================\n",
    "    # We want to \"normalise\" our first choice of function to obtain q_n\n",
    "\n",
    "    # ===================\n",
    "    #  FILL IN CODE HERE\n",
    "    # ===================\n",
    "    # We now need to update the B matrix (and B_inv as well...)\n",
    "    # For further use in the next iteration and beyond...\n",
    "    \n",
    "    # Plot our results for each iteration:\n",
    "    if n < 5:\n",
    "        fig = plt.figure(figsize=(14, 4))\n",
    "        ax = fig.add_subplot(1, 3, 1, projection='3d')\n",
    "        plot_R2_function(training_set[next_choice], ax, title = rf'$y(x, \\mu_{{{n}}})$')\n",
    "        ax = fig.add_subplot(1, 3, 2, projection='3d')\n",
    "        plot_R2_function(selected_func_resid, ax, \n",
    "                         title = rf'$y(x, \\mu_{{{n}}}) - \\mathcal{{I}}_{{{n-1}}}[y(x, \\mu_{{{n}}})]$')\n",
    "\n",
    "        ax.scatter(next_x[1] / n_x_grid, next_x[0] / n_x_grid, selected_func_resid[next_x], s=30)\n",
    "        ax = fig.add_subplot(1, 3, 3, projection='3d')\n",
    "        plot_R2_function(interp_funcs[-1], ax, title = rf'$q_{{{n}}}$')\n",
    "        plt.show()\n",
    "\n",
    "        display(Latex(rf'The point $x_{{{n}}}$ is at index {next_x} which ' +\n",
    "                      rf'gives the coordinate $x_{{{n}}} = {{{next_x[1]/n_x_grid, next_x[0]/n_x_grid}}}$'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Lets look at the results\n",
    "\n",
    "### First lets consider using the interpolator $\\mathcal{I}_n$ that we have built so far to interpolate various other functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets choose some arbitrary value for \\mu (within the range that we trained our interpolator!)\n",
    "mu_test = np.array([0.8, 1.1])\n",
    "y_test = eval_y_on_grid(mu_test)\n",
    "y_test_interp = interpolator(y_test, B_inv, interp_funcs, interp_points)\n",
    "\n",
    "display(Latex(rf'$\\mu_{{test}} = $ {mu_test}'))\n",
    "display(Latex(rf'$\\| y(x,\\mu_{{test}}) - \\mathcal{{I}}_{{{n-1}}}[y(x, \\mu_{{test}})] \\|_2 = $ ' + \n",
    "              rf'{norm(y_test - y_test_interp):0.5e}'))\n",
    "display(Latex(rf'$\\| y(x,\\mu_{{test}} - \\mathcal{{I}}_{{{n-1}}}[y(x, \\mu_{{test}})] \\|_{{L^\\inf}} = $ ' + \n",
    "              rf'{(y_test - y_test_interp).max():0.5e}'))\n",
    "\n",
    "fig = plt.figure(figsize=(14, 4))\n",
    "ax = fig.add_subplot(1, 3, 1, projection='3d')\n",
    "plot_R2_function(y_test, ax, title = rf'$y(x, \\mu_{{test}})$')\n",
    "y_interp_points = np.array([y_test[x] for x in interp_points])\n",
    "ax.scatter(np.array(interp_points)[:,1] / n_x_grid, np.array(interp_points)[:,0] / n_x_grid, y_interp_points, s=30, alpha=1.0)\n",
    "ax = fig.add_subplot(1, 3, 2, projection='3d')\n",
    "plot_R2_function(y_test_interp, ax, title = rf'$\\mathcal{{I}}_{{{n-1}}}[y(x, \\mu_{{test}})]$')\n",
    "ax = fig.add_subplot(1, 3, 3, projection='3d')\n",
    "plot_R2_function(y_test - y_test_interp, ax, title = rf'$y(x, \\mu_{{test}}) - \\mathcal{{I}}_{{{n-1}}}[y(x, \\mu_{{test}})]$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where exactly are our interpolation points $x_i$? And what are the chosen $\\mu_i$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_points_array = np.array(interp_points)\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.scatter(x = interp_points_array[:,1] / n_x_grid, y = interp_points_array[:,0] / n_x_grid)\n",
    "plt.title(r'Interpolation points $x_i$')\n",
    "plt.show()\n",
    "\n",
    "display(Latex(rf'Selected parameters $\\mu_i$ to build $q_i$:'))\n",
    "print(rf'{mu_grid_list[selected]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 - Lets look at error curves\n",
    "\n",
    "### We must generate a new dictionary - a _test set_ - and evaluate the quality of our interpolations. \n",
    "\n",
    "We take a random selection of $\\mu$ from $\\mathcal{U}$. Recall that the limits of $\\mathcal{U}$ are in ```mu_lims```. We call this test set $\\mathcal{T_e}$\n",
    "\n",
    "Then we look at the biggest $L^\\infty$ error for each of these $\\mu$, that is we consider\n",
    "\n",
    "$$\n",
    "\\large\n",
    "e_{n} = \\max_{\\mu \\in \\mathcal{T_e}} \\| y(x, \\mu) - \\mathcal{I}_n[y(x, \\mu)] \\|_{\\infty}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets generate a random set of mu on the domain of size n_test\n",
    "n_test = 100\n",
    "\n",
    "# What were the limits of the domain for mu again?\n",
    "print('mu_lims =', mu_lims)\n",
    "\n",
    "mu_test_list_1 = np.random.random(n_test) * (mu_lims[0][1] - mu_lims[0][0]) + mu_lims[0][0]\n",
    "mu_test_list_2 = np.random.random(n_test) * (mu_lims[1][1] - mu_lims[1][0]) + mu_lims[1][0]\n",
    "mu_test_list = np.vstack((mu_test_list_1, mu_test_list_2)).T\n",
    "\n",
    "print('First 10 mu_test_list =')\n",
    "print(mu_test_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.zeros((n_test, len(interp_funcs)))\n",
    "\n",
    "for n in range(1,len(interp_funcs)+1):\n",
    "    \n",
    "    # ===================\n",
    "    #  FILL IN CODE HERE\n",
    "    # ===================\n",
    "    # 1. Build the B matrix up to an n x n system\n",
    "    # for mu_i, mu_test in enumerate(mu_test_list):\n",
    "    # 2. Eval y for mu_test\n",
    "    # 3. interpolate y_test\n",
    "    # 4. calculate L_inf error\n",
    "        \n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.semilogy(range(1,len(interp_funcs)+1), errors.max(axis = 0))\n",
    "plt.title(rf'$\\max_{{\\mu}} \\, || \\, y(x, \\mu) - \\mathcal{{I}}_n[y(x, \\mu)] \\, ||_{{\\infty}}$ for $n=1\\ldots {len(interp_funcs)} $')\n",
    "plt.xticks(range(1,len(interp_funcs)+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - Bonus for the adventurous: \n",
    "### Solve a family of parametric PDEs and apply the EIM\n",
    "\n",
    "As a take-home exercise the following code could be used to approximate the solutions of the PDE\n",
    "\n",
    "$$\\large\n",
    "- \\mathrm{div}\\cdot(a(\\mu) \\nabla y) = f\n",
    "$$\n",
    "where\n",
    "$$\\large\n",
    "a(\\mu) = \\bar{a} + \\sum_{i=1}^4 \\mu_i \\chi_{\\mathcal{D}_i}(x)\n",
    "$$\n",
    "where the $\\mathcal{D}_i$ are partitions of the unit square in to the 4 even sub-squares.\n",
    "\n",
    "The solution $\\large y(x, \\mu)$ depends on $\\large x \\in \\mathcal{D} = [0,1]^2$, and the parameter $\\large \\mu \\in \\mathcal{U} \\subset \\mathbb{R}^4$ can have some range that we define. Below is a very primitive finite element method (FEM) solver of the PDE that gives a coarse solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "# The spatial grid on which we solve the PDE is of size (2**div x 2**div)\n",
    "div = 5\n",
    "n_side = 2**div - 1\n",
    "n_el = n_side * n_side\n",
    "h = 1.0 / (n_side + 1)\n",
    "\n",
    "def solve_PDE_FEM(mu):\n",
    "    # a is assumed to be a 2x2 array of positive values. This routine returns the solution\n",
    "    # of the PDE on a grid of size 2^div by 2^div\n",
    "    a = mu.repeat(2**(div - 1), axis=0).repeat(2**(div - 1), axis=1)\n",
    "\n",
    "    # Now we make the various diagonals\n",
    "    diag = 2.0 * (a[:-1, :-1] + a[:-1,1:] + a[1:,:-1] + a[1:, 1:]).flatten()\n",
    "    # min_diag is below the diagonal, hence deals with element to the left in the FEM grid\n",
    "    lr_diag = -(a[1:, 1:] + a[:-1, 1:]).flatten()\n",
    "    lr_diag[n_side-1::n_side] = 0 # These corresponds to edges on left or right extreme\n",
    "    lr_diag = lr_diag[:-1]\n",
    "\n",
    "    # Far min deals with the element that is above\n",
    "    ud_diag = -(a[1:-1, 1:] + a[1:-1, :-1]).flatten()\n",
    "\n",
    "    A = scipy.sparse.diags([diag, lr_diag, lr_diag, ud_diag, ud_diag], [0, -1, 1, -n_side, n_side]).tocsr()\n",
    "    f = 0.5 * h * h * np.ones(n_el)\n",
    "\n",
    "    u_flat = scipy.sparse.linalg.spsolve(A, f)\n",
    "    return np.pad(u_flat.reshape((n_side, n_side)), ((1,1),(1,1)), 'constant')\n",
    "\n",
    "pde_x1_grid, pde_x2_grid = np.meshgrid(np.linspace(0, 1, 2**div+1, endpoint=True), \n",
    "                                       np.linspace(0, 1, 2**div+1, endpoint=True))\n",
    "\n",
    "def plot_PDE_soln(vals, ax, title=None, alpha=0.7):\n",
    "    # A routine that just plots a function that is assumed to be evaluated \n",
    "    # on a the grid of points - vals is assumed to be a square array\n",
    "    # (note that x1_grid and x2_grid will be defined below)\n",
    "    wframe = ax.plot_surface(pde_x1_grid, pde_x2_grid, vals, cstride=2, rstride=2, \n",
    "                             alpha=alpha, cmap=cmap)\n",
    "    \n",
    "    ax.set_facecolor('white')\n",
    "    if title is not None:\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([[1, 0.3], [0.2, 0.8]])\n",
    "y = solve_PDE_FEM(mu)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "plot_PDE_soln(y, ax, title='FEM solution $y(x,\\mu)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets generate a random set of mu, since we are in 4 dimensions\n",
    "N_train = 1000\n",
    "\n",
    "# Evenly distributed in (0.1, 1.1)^4\n",
    "mu_train_list = np.random.random((N_train, 4)) + 0.1\n",
    "\n",
    "training_set = [solve_PDE_FEM(mu) for mu in mu_train_list]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
